{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data] Downloading package brown to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from emoji import UNICODE_EMOJI\n",
    "from textblob import TextBlob\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data cleaning/manipulation technique/functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tags(text):\n",
    "    return re.findall(\"#([a-zA-Z0-9_]{1,50})\", text)\n",
    "\n",
    "    # will return a list of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emoji(text):\n",
    "    return [ch for ch in text if ch in UNICODE_EMOJI['en']]\n",
    "\n",
    "    # will return a list of emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove url, mentions, tags, punctuation, numbers, emojis\n",
    "# we need clean text to extract words & perform sentiment analysis\n",
    "\n",
    "def clean_tweet(txt): \n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", txt)\n",
    "    temp1 = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp2 = re.sub(r\"http\\S+\", \"\", temp1)\n",
    "    \n",
    "    result=''.join(i for i in temp2.lower() if (i.isalpha() or i==' '))\n",
    "    return result\n",
    "\n",
    "    # return the cleaned tweet in lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_list(tweet):\n",
    "    \n",
    "    lst = word_tokenize(tweet)\n",
    "    lst1 = []\n",
    "    stops = list(stopwords.words('english'))\n",
    "    for w in lst:\n",
    "        if w not in stops:\n",
    "            lst1.append(w)\n",
    "    \n",
    "    return lst1\n",
    "\n",
    "    # return a list of words (without stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(tweet):\n",
    "    blob = TextBlob(tweet)\n",
    "    \n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "    # return the sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(date):\n",
    "    \n",
    "    return date[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hour(date):\n",
    "    \n",
    "    return date[11:13]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_10min(date):\n",
    "    \n",
    "    return date[14]+'0'\n",
    "\n",
    "    # if we want to do in-depth analysis on certain day, this might come in handy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min(date):\n",
    "    \n",
    "    return date[14:16]\n",
    "\n",
    "    # if we want to do in-depth analysis on certain day, this might come in handy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the below 5 functions add a sentiment score label to each tweet entry\n",
    "# 5 different labels: firm positive, positive, neutral, negative, firm negative\n",
    "\n",
    "def firm_pos(score):\n",
    "    if score >= 0.7:\n",
    "        return 1\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(score):\n",
    "    if (score >= 0.25) & (score < 0.7):\n",
    "        return 1\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neutral(score):\n",
    "    if (score >= -0.25) & (score < 0.25):\n",
    "        return 1\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg(score):\n",
    "    if (score > -0.7) & (score < -0.25):\n",
    "        return 1\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firm_neg(score):\n",
    "    if score <= -0.7:\n",
    "        return 1\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import data, then check duplicate and missing value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Project Data/Kershaw 2017 WS.csv')\n",
    "df['id'].duplicated(keep='last').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id      0\n",
       "date    3\n",
       "text    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **If problem exists, remove duplicate and drop nan rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78149, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78146, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(how='any').reset_index()\n",
    "df.drop(columns=['index'],inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the techniques on the data, after that we'll have the used words, tags, emojis, sentiment score & label, and specific date/hour/min data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "      <th>emojis</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>words</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>10min</th>\n",
       "      <th>min</th>\n",
       "      <th>POS</th>\n",
       "      <th>pos</th>\n",
       "      <th>neu</th>\n",
       "      <th>neg</th>\n",
       "      <th>NEG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>922975991626063872</td>\n",
       "      <td>2017-10-24 23:59:59+00:00</td>\n",
       "      <td>@EmresBrylcreem @aj_joven I can't believe we'r...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>i cant believe were facing kershaw in game o...</td>\n",
       "      <td>[cant, believe, facing, kershaw, game, one, im...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2017-10-24</td>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>922975974605643777</td>\n",
       "      <td>2017-10-24 23:59:55+00:00</td>\n",
       "      <td>That was the best national anthem I have ever ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[😄]</td>\n",
       "      <td>that was the best national anthem i have ever ...</td>\n",
       "      <td>[best, national, anthem, ever, heard, watch, c...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2017-10-24</td>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>922975971963232257</td>\n",
       "      <td>2017-10-24 23:59:54+00:00</td>\n",
       "      <td>Been a Puig fan since day 1, love Kershaw &amp;amp...</td>\n",
       "      <td>[WorldSeries]</td>\n",
       "      <td>[]</td>\n",
       "      <td>been a puig fan since day  love kershaw amp ja...</td>\n",
       "      <td>[puig, fan, since, day, love, kershaw, amp, ja...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2017-10-24</td>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>922975956645568512</td>\n",
       "      <td>2017-10-24 23:59:50+00:00</td>\n",
       "      <td>So ecstatic in finally seeing Clayton Kershaw ...</td>\n",
       "      <td>[ThisTeam, WorldSeries]</td>\n",
       "      <td>[]</td>\n",
       "      <td>so ecstatic in finally seeing clayton kershaw ...</td>\n",
       "      <td>[ecstatic, finally, seeing, clayton, kershaw, ...</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>2017-10-24</td>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>922975956020576256</td>\n",
       "      <td>2017-10-24 23:59:50+00:00</td>\n",
       "      <td>#MLB\\n\\nWorld Series - Game 1\\n[1902] 1H Los A...</td>\n",
       "      <td>[MLB]</td>\n",
       "      <td>[]</td>\n",
       "      <td>world series  game  h los angeles dodgers   d ...</td>\n",
       "      <td>[world, series, game, h, los, angeles, dodgers...</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>2017-10-24</td>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                       date  \\\n",
       "0  922975991626063872  2017-10-24 23:59:59+00:00   \n",
       "1  922975974605643777  2017-10-24 23:59:55+00:00   \n",
       "2  922975971963232257  2017-10-24 23:59:54+00:00   \n",
       "3  922975956645568512  2017-10-24 23:59:50+00:00   \n",
       "4  922975956020576256  2017-10-24 23:59:50+00:00   \n",
       "\n",
       "                                                text                     tags  \\\n",
       "0  @EmresBrylcreem @aj_joven I can't believe we'r...                       []   \n",
       "1  That was the best national anthem I have ever ...                       []   \n",
       "2  Been a Puig fan since day 1, love Kershaw &amp...            [WorldSeries]   \n",
       "3  So ecstatic in finally seeing Clayton Kershaw ...  [ThisTeam, WorldSeries]   \n",
       "4  #MLB\\n\\nWorld Series - Game 1\\n[1902] 1H Los A...                    [MLB]   \n",
       "\n",
       "  emojis                                         clean_text  \\\n",
       "0     []    i cant believe were facing kershaw in game o...   \n",
       "1    [😄]  that was the best national anthem i have ever ...   \n",
       "2     []  been a puig fan since day  love kershaw amp ja...   \n",
       "3     []  so ecstatic in finally seeing clayton kershaw ...   \n",
       "4     []  world series  game  h los angeles dodgers   d ...   \n",
       "\n",
       "                                               words  sentiment_score  \\\n",
       "0  [cant, believe, facing, kershaw, game, one, im...              0.2   \n",
       "1  [best, national, anthem, ever, heard, watch, c...              0.4   \n",
       "2  [puig, fan, since, day, love, kershaw, amp, ja...              0.5   \n",
       "3  [ecstatic, finally, seeing, clayton, kershaw, ...             -0.2   \n",
       "4  [world, series, game, h, los, angeles, dodgers...             -0.4   \n",
       "\n",
       "          day hour 10min min  POS  pos  neu  neg  NEG  \n",
       "0  2017-10-24   23    50  59    0    0    1    0    0  \n",
       "1  2017-10-24   23    50  59    0    1    0    0    0  \n",
       "2  2017-10-24   23    50  59    0    1    0    0    0  \n",
       "3  2017-10-24   23    50  59    0    0    1    0    0  \n",
       "4  2017-10-24   23    50  59    0    0    0    1    0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tags']= df.apply(lambda row: extract_tags(row['text']), axis=1)\n",
    "df['emojis']= df.apply(lambda row: extract_emoji(row['text']), axis=1)\n",
    "df['clean_text']= df.apply(lambda row: clean_tweet(row['text']), axis=1)\n",
    "df['words']= df.apply(lambda row: word_list(row['clean_text']), axis=1)\n",
    "df['sentiment_score']= df.apply(lambda row: sentiment(row['clean_text']), axis=1)\n",
    "df['day']= df.apply(lambda row: get_date(row['date']), axis=1)\n",
    "df['hour']= df.apply(lambda row: get_hour(row['date']), axis=1)\n",
    "df['10min']= df.apply(lambda row: get_10min(row['date']), axis=1)\n",
    "df['min']= df.apply(lambda row: get_min(row['date']), axis=1)\n",
    "df['POS']= df.apply(lambda row: firm_pos(row['sentiment_score']), axis=1)\n",
    "df['pos']= df.apply(lambda row: pos(row['sentiment_score']), axis=1)\n",
    "df['neu']= df.apply(lambda row: neutral(row['sentiment_score']), axis=1)\n",
    "df['neg']= df.apply(lambda row: neg(row['sentiment_score']), axis=1)\n",
    "df['NEG']= df.apply(lambda row: firm_neg(row['sentiment_score']), axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
